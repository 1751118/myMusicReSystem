{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a498339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T03:34:25.694685Z",
     "start_time": "2024-05-08T03:34:23.671659Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class DCNN(nn.Module):\n",
    "    def __init__(self, img_depth, num_classes):\n",
    "        super(DCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=img_depth, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Flattening the output for the dense layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 正确计算展平后的尺寸\n",
    "        self.dense1 = nn.Linear(256 * 6 * 6, 128)  # Adjusted size after pooling\n",
    "        self.batchnorm7 = nn.BatchNorm1d(128)\n",
    "        self.dropout4 = nn.Dropout(0.6)\n",
    "        \n",
    "        self.out_layer = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.batchnorm1(self.conv1(x)))\n",
    "        x = F.elu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.dropout1(self.pool1(x))\n",
    "        \n",
    "        x = F.elu(self.batchnorm3(self.conv3(x)))\n",
    "        x = F.elu(self.batchnorm4(self.conv4(x)))\n",
    "        x = self.dropout2(self.pool2(x))\n",
    "        \n",
    "        x = F.elu(self.batchnorm5(self.conv5(x)))\n",
    "        x = F.elu(self.batchnorm6(self.conv6(x)))\n",
    "        x = self.dropout3(self.pool3(x))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.elu(self.batchnorm7(self.dense1(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.out_layer(x)\n",
    "        return x  # 返回 logits 用于计算交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e398f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T03:34:26.078378Z",
     "start_time": "2024-05-08T03:34:25.700248Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch as t\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载Haar特征的级联分类器，用于面部检测\n",
    "detection_model_path = './haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = './models/face_emotion_rec_model_5.pth'\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path) # 人脸检测模型\n",
    "\n",
    "# 加载情绪识别模型\n",
    "emotion_classifier = t.load(emotion_model_path, map_location= device)\n",
    "EMOTIONS = ['disgust',  'happiness', 'sadness', 'surprise',  'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f69028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T03:34:26.091847Z",
     "start_time": "2024-05-08T03:34:26.084301Z"
    }
   },
   "outputs": [],
   "source": [
    "def emotion_testing(test_img):\n",
    "    \n",
    "    # 定义一个变量来控制是否显示当前帧\n",
    "    predicted_emotion = None\n",
    "        \n",
    "    # 照片转化为RGB灰度图\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 检测\n",
    "    faces_detected = face_detection.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        # 裁剪人脸并调整格式\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=3)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]\n",
    "        \n",
    "        # 转化为48 x 48的灰度图并转化为像素点\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = np.expand_dims(roi_gray, axis=2)\n",
    "        \n",
    "        # 提升维度，将值的范围控制到0~1\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels = img_pixels.astype(np.float32)\n",
    "        img_pixels /= 255\n",
    "        \n",
    "        img_pixels = t.from_numpy(img_pixels)\n",
    "        img_pixels = img_pixels.permute(0, 3, 1, 2)  # Reorder from NHWC to NCHW\n",
    "        print(f'img_pixels:{img_pixels.shape}')\n",
    "        # 预测情绪\n",
    "        # 前向传播得到输出\n",
    "        with torch.no_grad():  # 关闭梯度计算\n",
    "            output = emotion_classifier(img_pixels.to(device))\n",
    "            print(f'output:{F.softmax(output, dim=1)}')\n",
    "            _, prediction = torch.max(F.softmax(output, dim=1), 1)\n",
    "        \n",
    "        predicted_emotion = EMOTIONS[prediction]\n",
    "        \n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,0), 3)\n",
    "        resized_img = cv2.resize(test_img, (0, 0), fx=0.25, fy=0.25, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "    return predicted_emotion, resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9a9905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T03:53:03.280370Z",
     "start_time": "2024-05-08T03:34:26.094161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on all addresses.\n",
      "Use http://10.80.43.30:8080/ to access the application\n",
      "img_pixels:torch.Size([1, 1, 48, 48])\n",
      "output:tensor([[4.7055e-04, 5.8363e-01, 1.9249e-02, 1.1637e-02, 3.8501e-01]],\n",
      "       device='cuda:0')\n",
      "Emotion detected is happiness\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3316321/2115344561.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# 启动 PyWebIO 应用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_and_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pywebio/platform/tornado.py\u001b[0m in \u001b[0;36mstart_server\u001b[0;34m(applications, port, host, debug, cdn, static_dir, remote_access, reconnect_timeout, allowed_origins, check_origin, auto_open_webbrowser, max_payload_size, **tornado_app_settings)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mstart_remote_access_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIOLoop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmanage_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanage_asyncgens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 scheduled[0]._when - self.time(), 0), 86400) if scheduled\n\u001b[1;32m     97\u001b[0m             else None)\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mevent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 找到对应的情绪\n",
    "from pywebio.input import file_upload\n",
    "from pywebio.output import *\n",
    "from pywebio import start_server\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def upload_and_predict():\n",
    "    # 文件上传\n",
    "    file = file_upload(\"Upload a photo to recognize your emotion\", accept=\"image/*\")\n",
    "    if file is not None:\n",
    "        # 预处理图片\n",
    "        image = Image.open(io.BytesIO(file['content']))\n",
    "        image = np.array(image)\n",
    "        \n",
    "        emotion_word, resized_img = emotion_testing(image)\n",
    "        print(f'Emotion detected is {emotion_word}')\n",
    "        image_pil = Image.fromarray(resized_img)\n",
    "        with use_scope('playlist', clear = True):\n",
    "            put_image(image_pil)\n",
    "            put_markdown('Wait for a moment......')\n",
    "        time.sleep(3)\n",
    "        with use_scope('playlist', clear = True):\n",
    "            put_text('playlist')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 启动 PyWebIO 应用\n",
    "    nest_asyncio.apply()\n",
    "    asyncio.create_task(start_server(upload_and_predict, port=8080, debug=True, notebook=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
