{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b173069b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:49:52.805399Z",
     "start_time": "2024-06-03T15:49:50.781871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 361346 entries, 0 to 361345\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   score          361346 non-null  float64\n",
      " 1   hashtag        361346 non-null  object \n",
      " 2   lang           361346 non-null  object \n",
      " 3   tweet_lang     361346 non-null  object \n",
      " 4   time_zone      361346 non-null  object \n",
      " 5   track_id       361346 non-null  object \n",
      " 6   timestamp      361346 non-null  object \n",
      " 7   season         361346 non-null  object \n",
      " 8   day_time       361346 non-null  object \n",
      " 9   weekday        361346 non-null  int64  \n",
      " 10  day_of_year    361346 non-null  int64  \n",
      " 11  week_of_month  361346 non-null  int64  \n",
      " 12  week_of_year   361346 non-null  int64  \n",
      " 13  weekend        361346 non-null  bool   \n",
      " 14  day            361346 non-null  int64  \n",
      " 15  minute         361346 non-null  int64  \n",
      " 16  month          361346 non-null  int64  \n",
      " 17  hours          361346 non-null  int64  \n",
      "dtypes: bool(1), float64(1), int64(8), object(8)\n",
      "memory usage: 47.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26911 entries, 0 to 26910\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   track_id  26911 non-null  object\n",
      " 1   labels    26911 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 420.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "# 设置全局图表大小\n",
    "plt.rc('figure', figsize=(12, 8))\n",
    "plt.rc('axes', titlesize=18)  # 设置轴标题的字体大小\n",
    "plt.rc('axes', labelsize=14)  # 设置轴标签的字体大小\n",
    "plt.rc('xtick', labelsize=12)  # 设置x轴刻度标签的字体大小\n",
    "plt.rc('ytick', labelsize=12)  # 设置y轴刻度标签的字体大小\n",
    "plt.rc('legend', fontsize=12)  # 设置图例的字体大小\n",
    "\n",
    "df = pd.read_csv('./data/classify_data.csv')\n",
    "\n",
    "# 衍生列\n",
    "add_columns = ['season', 'day_time', 'weekday', 'day_of_year', 'week_of_month', 'week_of_year'\n",
    "              ,'weekend', 'day', 'minute',  'month', 'hours']\n",
    "\n",
    "# df.drop(add_columns, axis = 1, inplace = True)\n",
    "df.info()\n",
    "\n",
    "# track_to_label = pd.read_csv('./data/track_to_labels_dbscan.csv')\n",
    "track_to_label = pd.read_csv('./data/track_to_labels_kmeans_2.csv')\n",
    "track_to_label.info()\n",
    "\n",
    "df = df.merge(track_to_label, on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a387c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:49:55.980961Z",
     "start_time": "2024-06-03T15:49:52.808016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mood  mood_label\n",
      "0       happiness           3\n",
      "1       happiness           3\n",
      "2       happiness           3\n",
      "3       happiness           3\n",
      "4       happiness           3\n",
      "...           ...         ...\n",
      "361341    disgust           0\n",
      "361342   surprise           4\n",
      "361343    sadness           1\n",
      "361344    sadness           1\n",
      "361345    sadness           1\n",
      "\n",
      "[361346 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 361346 entries, 0 to 361345\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   score          361346 non-null  float64\n",
      " 1   hashtag        361346 non-null  object \n",
      " 2   lang           361346 non-null  object \n",
      " 3   tweet_lang     361346 non-null  object \n",
      " 4   time_zone      361346 non-null  object \n",
      " 5   track_id       361346 non-null  object \n",
      " 6   season         361346 non-null  object \n",
      " 7   day_time       361346 non-null  object \n",
      " 8   weekday        361346 non-null  int64  \n",
      " 9   day_of_year    361346 non-null  int64  \n",
      " 10  week_of_month  361346 non-null  int64  \n",
      " 11  week_of_year   361346 non-null  int64  \n",
      " 12  weekend        361346 non-null  bool   \n",
      " 13  day            361346 non-null  int64  \n",
      " 14  minute         361346 non-null  int64  \n",
      " 15  month          361346 non-null  int64  \n",
      " 16  hours          361346 non-null  int64  \n",
      " 17  labels         361346 non-null  int64  \n",
      " 18  score_2        361346 non-null  float64\n",
      " 19  score_3        361346 non-null  float64\n",
      " 20  mood_label     361346 non-null  int8   \n",
      " 21  happy          361346 non-null  int8   \n",
      "dtypes: bool(1), float64(3), int64(9), int8(2), object(7)\n",
      "memory usage: 56.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#对分数score取平方、3次方\n",
    "df['score_2'] = df['score'] ** 2\n",
    "df['score_3'] = df['score'] ** 3\n",
    "\n",
    "# 对情绪分数score进行分箱操作\n",
    "labels = ['disgust', 'sadness', 'neutral', 'happiness', 'surprise']\n",
    "bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "df['mood'] = pd.cut(df['score'], labels=labels, bins = bins, include_lowest=True)\n",
    "df['mood'] = df['mood'].astype('category')\n",
    "\n",
    "df['mood_label'] = df['mood'].cat.codes\n",
    "print(df[['mood', 'mood_label']])\n",
    "\n",
    "bins = [0.0, 0.5, 1.0]\n",
    "df['happy'] = pd.cut(df['score'], labels=[0, 1], bins = bins, include_lowest=True)\n",
    "df['happy'] = df['happy'].cat.codes\n",
    "\n",
    "if (df['labels'] >= 2).sum() > 0:\n",
    "    df.to_csv('./data/final_classify_data_5.csv', index = False)\n",
    "else:\n",
    "    df.to_csv('./data/final_classify_data_2.csv', index = False)\n",
    "\n",
    "df.drop(['timestamp', 'mood'], axis = 1, inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db230346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:50:09.285301Z",
     "start_time": "2024-06-03T15:49:55.983278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 241581, 1: 119765})\n",
      "Resampled class distribution: Counter({0: 241581, 1: 241581})\n"
     ]
    }
   ],
   "source": [
    "# 对几个类别特别多的列采用二进制编码\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 查看原始数据集的类别分布\n",
    "print(f\"Original class distribution: {Counter(df['labels'])}\")\n",
    "\n",
    "X = df.drop(['labels', 'track_id'], axis = 1)\n",
    "y = df['labels']\n",
    "\n",
    "# 不交叉组合\n",
    "def encoder_category(df):\n",
    "    columns = ['hashtag', 'tweet_lang', 'time_zone', 'lang']\n",
    "\n",
    "    # # 特征衍生\n",
    "    columns += ['day_time', 'season']\n",
    "    for column in columns:\n",
    "        if column == 'timestamp':\n",
    "            continue\n",
    "        encoder = LabelEncoder()\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "\n",
    "    df['weekend'] = df['weekend'].astype(int)\n",
    "    return df\n",
    "\n",
    "X = encoder_category(X)\n",
    "X, y = SMOTE(random_state=42).fit_resample(X, y)\n",
    "print(f\"Resampled class distribution: {Counter(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a7765e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:50:09.290499Z",
     "start_time": "2024-06-03T15:50:09.288212Z"
    }
   },
   "outputs": [],
   "source": [
    "# X.shape, y.shape\n",
    "# pd.concat([X, y], axis = 1).to_csv('./data/ClusterCentroids_undersample_data_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0ceea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:50:09.297837Z",
     "start_time": "2024-06-03T15:50:09.292391Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('./data/ClusterCentroids_undersample_data_2.csv')\n",
    "# y = df['labels']\n",
    "# X = df.drop('labels', axis = 1)\n",
    "# print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d7e9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:50:12.151841Z",
     "start_time": "2024-06-03T15:50:09.299659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hashtag', 'lang', 'tweet_lang', 'time_zone', 'season', 'day_time'] \n",
      " ['score', 'weekday', 'day_of_year', 'week_of_month', 'week_of_year', 'weekend', 'day', 'minute', 'month', 'hours', 'score_2', 'score_3', 'mood_label', 'happy']\n",
      "(4182, 29, 38, 121, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "categorical_features = ['hashtag', 'lang', 'tweet_lang', 'time_zone', 'season', 'day_time']\n",
    "numerical_features = [i for i in X.columns if i not in categorical_features if i != 'timestamp']\n",
    "print(categorical_features, '\\n', numerical_features)\n",
    "\n",
    "X[numerical_features] = MinMaxScaler().fit_transform(X[numerical_features])\n",
    "categories = tuple(X.loc[:, categorical_features].nunique())\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e330c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:04:18.540370Z",
     "start_time": "2024-05-27T13:04:18.540355Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam,SGD\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print(X_train.info())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "X_train_cat = X_train[categorical_features]\n",
    "X_train_con = X_train[numerical_features]\n",
    "X_test_cat = X_test[categorical_features]\n",
    "X_test_con = X_test[numerical_features]\n",
    "\n",
    "# 将数据转换为 PyTorch 张量\n",
    "X_train_categ = torch.tensor(X_train_cat.values, dtype=torch.long)\n",
    "X_train_cont = torch.tensor(X_train_con.values, dtype=torch.float32)\n",
    "X_test_categ = torch.tensor(X_test_cat.values, dtype=torch.long)\n",
    "X_test_cont = torch.tensor(X_test_con.values, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_categ, X_train_cont, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_categ, X_test_cont, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa720c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:04:18.541770Z",
     "start_time": "2024-05-27T13:04:18.541754Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "# 获取当前时间，并格式化为字符串\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# 使用时间戳生成日志文件名\n",
    "log_filename = f'./exp/Tabtransformer_{current_time}.log'\n",
    "\n",
    "# 配置logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    filename=log_filename,  # 动态生成的日志文件名\n",
    "                    filemode='w')\n",
    "\n",
    "logger = logging.getLogger()\n",
    "log_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cef00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:04:18.543195Z",
     "start_time": "2024-05-27T13:04:18.543178Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义 TabTransformer 模型\n",
    "model = TabTransformer(\n",
    "    categories = categories,                # 分类特征的类别数量\n",
    "    num_continuous = len(numerical_features), # 连续特征数量\n",
    "    dim = 32,                           # 模型维度\n",
    "    dim_out = 2,                        # 输出维度（2类分类）\n",
    "    depth = 6,                          # 模型深度\n",
    "    heads = 8,                          # 注意力头数量\n",
    "    attn_dropout = 0.5,                 # 注意力层 dropout\n",
    "    ff_dropout = 0.5,                   # 前馈层 dropout\n",
    "    mlp_hidden_mults = (4, 2, 1),          # MLP 隐藏层相对维度\n",
    "    mlp_act = nn.ReLU(),           # MLP 激活函数\n",
    "    continuous_mean_std = cont_mean_std # 连续特征的均值和标准差\n",
    ")\n",
    "\n",
    "logger.info(model)\n",
    "model\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # 对线性层的权重应用正态分布初始化\n",
    "        nn.init.normal_(m.weight, mean=0.3, std=0.25)\n",
    "        # 如果存在偏置项，则将其初始化为0\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        # 对嵌入层也可以应用正态分布初始化\n",
    "        nn.init.normal_(m.weight, mean=0.3, std=0.25)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c531cd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:04:18.544284Z",
     "start_time": "2024-05-27T13:04:18.544269Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_and_save_fig(train_losses, train_accs, test_losses, test_accs):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # 设置全局图表大小\n",
    "    plt.rc('figure', figsize=(12, 8))\n",
    "    plt.rc('axes', titlesize=18)  # 设置轴标题的字体大小\n",
    "    plt.rc('axes', labelsize=14)  # 设置轴标签的字体大小\n",
    "    plt.rc('xtick', labelsize=12)  # 设置x轴刻度标签的字体大小\n",
    "    plt.rc('ytick', labelsize=12)  # 设置y轴刻度标签的字体大小\n",
    "    plt.rc('legend', fontsize=12)  # 设置图例的字体大小\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Loss and acc of the train process')\n",
    "    plt.plot(range(num_epochs), train_losses, 'b--', label='train_loss')\n",
    "    plt.plot(range(num_epochs), [x for x in train_accs], 'g', label = 'train_acc')\n",
    "    plt.plot(range(num_epochs), test_losses, 'r--', label = 'test_loss')\n",
    "    plt.plot(range(num_epochs), [x for x in test_accs], 'black', label = 'test_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc / loss')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    save_path = f'./exp/figures/{current_time}'  # 替换为你的路径\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1421eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:04:18.545701Z",
     "start_time": "2024-05-27T13:04:18.545685Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# 转换数据到 GPU\n",
    "X_train_categ = X_train_categ.to(device)\n",
    "X_train_cont = X_train_cont.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_test_categ = X_test_categ.to(device)\n",
    "X_test_cont = X_test_cont.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# 定义优化器\n",
    "lr = 3e-4\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 100\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "logger.info(\"Trainning params:\")\n",
    "logger.info(f\"lr: {lr}\")\n",
    "logger.info(f\"batch_size: {batch_size}\")\n",
    "logger.info(f\"num_epochs: {num_epochs}\")          \n",
    "logger.info(\"Start trainning......\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    logger.info(f\"---------------------------------- Epoch {epoch + 1} / Epoch {num_epochs} ----------------------------------\")\n",
    "    total_loss, total = 0.0, 0\n",
    "    correct, num = 0, 0\n",
    "    for X_batch_categ, X_batch_cont, y_batch in train_loader:\n",
    "        X_batch_categ = X_batch_categ.to(device)\n",
    "        X_batch_cont = X_batch_cont.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch_categ, X_batch_cont)\n",
    "        loss = F.cross_entropy(logits, y_batch)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "        correct += (preds == y_batch).sum().item()  # 计算正确预测的数量\n",
    "        total += y_batch.size(0)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_acc = correct / total\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # 评估模型\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    s = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
    "    with torch.no_grad():\n",
    "        for X_batch_categ, X_batch_cont, y_batch in test_loader:\n",
    "            X_batch_categ = X_batch_categ.to(device)\n",
    "            X_batch_cont = X_batch_cont.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            test_logits = model(X_batch_categ, X_batch_cont)\n",
    "            test_loss += F.cross_entropy(test_logits, y_batch, reduction='sum').item()\n",
    "            preds = torch.argmax(test_logits, dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "            \n",
    "            for i in range(5):\n",
    "                s[i] += (preds == i).sum()\n",
    "    \n",
    "    for i in range(5):\n",
    "        logger.info(f\"测试集预测为{i}的样本数为：{s[i]}\")\n",
    "    test_loss /= total\n",
    "    accuracy = correct / total\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(accuracy)\n",
    "    logger.info(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "logger.info(\"Trainning finish!\")\n",
    "torch.save(model, f'./models/tabtransformer_2_{accuracy:.2f}.pth')\n",
    "show_and_save_fig(train_losses, train_accs, test_losses, test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62db6cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T14:14:00.156478Z",
     "start_time": "2024-05-31T14:14:00.153815Z"
    }
   },
   "source": [
    "#### wandb 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17892317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:50:34.267457Z",
     "start_time": "2024-06-03T15:50:28.243412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoumengjiuzhui\u001b[0m (\u001b[33myoumeng\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'activation': {'values': ['ReLU', 'LeakyReLU', 'TanH']},\n",
      "                'add_norm_dropout': {'distribution': 'uniform',\n",
      "                                     'max': 1.0,\n",
      "                                     'min': 0.2},\n",
      "                'attn_dropout': {'distribution': 'uniform',\n",
      "                                 'max': 1.0,\n",
      "                                 'min': 0.2},\n",
      "                'batch_size': {'values': [32, 64, 128, 256, 512, 1024]},\n",
      "                'ckpt_path': {'value': './models/tabtransformer_not_balance_2024-06-03_23-50-33.pt'},\n",
      "                'embedding_initialization': {'values': ['kaiming_uniform',\n",
      "                                                        'kaiming_normal']},\n",
      "                'epochs': {'value': 100},\n",
      "                'ff_dropout': {'distribution': 'uniform',\n",
      "                               'max': 1.0,\n",
      "                               'min': 0.2},\n",
      "                'initialization': {'values': ['kaiming', 'xavier', 'random']},\n",
      "                'input_embed_dim': {'values': [16, 32, 64, 128]},\n",
      "                'layers': {'values': ['32-64-16', '128-64-32-16']},\n",
      "                'lr': {'distribution': 'log_uniform_values',\n",
      "                       'max': 0.0001,\n",
      "                       'min': 1e-06},\n",
      "                'num_attn_blocks': {'values': [2, 4, 6, 8, 10]},\n",
      "                'num_heads': {'values': [4, 8, 16, 32]},\n",
      "                'optim_type': {'values': ['Adam', 'AdamW']},\n",
      "                'project_name': {'value': 'pytorch-tabular-tabtransformer'},\n",
      "                'weight_decay': {'distribution': 'log_uniform_values',\n",
      "                                 'max': 0.001,\n",
      "                                 'min': 1e-06}}}\n",
      "Create sweep with ID: gawoh8t1\n",
      "Sweep URL: https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/sweeps/gawoh8t1\n"
     ]
    }
   ],
   "source": [
    "# File path: tab_transformer_classification.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "from tqdm import tqdm as tqdm\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "from pytorch_tabular.utils import print_metrics\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from argparse import Namespace\n",
    "# 方法2：忽略信号\n",
    "from signal import signal, SIGPIPE, SIG_DFL, SIG_IGN\n",
    "signal(SIGPIPE, SIG_IGN)\n",
    "\n",
    "wandb.login()\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "config = Namespace(\n",
    "    # 实验参数\n",
    "    project_name = 'pytorch-tabular-tabtransformer',\n",
    "    \n",
    "    # 训练参数\n",
    "    batch_size = 512,\n",
    "    lr = 1e-4,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 100,\n",
    "    ckpt_path = f'./models/tabtransformers_{current_time}',\n",
    "    \n",
    "    # 模型参数\n",
    "    input_embed_dim = 32,\n",
    "    num_heads = 8,\n",
    "    num_attn_blocks=6,\n",
    "    embedding_initialization = 'kaiming_normal',\n",
    "\n",
    "    # LinearHeadConfig\n",
    "    layers = '32-64-32',\n",
    "    initialization = 'kaiming',\n",
    "    activation = 'ReLU'\n",
    ")\n",
    "\n",
    "# wandb.sweep\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    }\n",
    "}\n",
    "sweep_config['parameters'] = {}\n",
    "\n",
    "# 固定不变的参数\n",
    "sweep_config['parameters'].update({\n",
    "    'project_name': {'value': config.project_name},\n",
    "    'epochs': {'value': 100},\n",
    "    'ckpt_path': {'value': f'./models/tabtransformer_not_balance_{current_time}.pt'},\n",
    "})\n",
    "# 离散型分布的参数\n",
    "sweep_config['parameters'].update({\n",
    "    'optim_type': {'values': ['Adam', 'AdamW']},\n",
    "    'input_embed_dim':{ 'values': [16, 32, 64, 128]},\n",
    "    'num_heads' : {'values': [4, 8, 16, 32]},\n",
    "    'num_attn_blocks': { 'values': [2, 4, 6, 8, 10]},\n",
    "    'embedding_initialization': {'values': ['kaiming_uniform', 'kaiming_normal']},\n",
    "    'batch_size': {'values': [32, 64, 128, 256, 512, 1024]},\n",
    "    'activation': {'values': ['ReLU', 'LeakyReLU', 'TanH']},\n",
    "    'initialization': {'values': ['kaiming', 'xavier', 'random']},\n",
    "    'layers': {'values': ['32-64-16', '128-64-32-16']}\n",
    "})\n",
    "# 连续型参数\n",
    "sweep_config['parameters'].update({\n",
    "    'lr':{\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-6,\n",
    "        'max': 1e-4\n",
    "    },\n",
    "    'weight_decay':{\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-6,\n",
    "        'max': 1e-3\n",
    "    },\n",
    "    'attn_dropout':{\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.2,\n",
    "        'max': 1.0\n",
    "    },\n",
    "    'add_norm_dropout':{\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.2,\n",
    "        'max': 1.0\n",
    "    },\n",
    "    'ff_dropout':{\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.2,\n",
    "        'max': 1.0\n",
    "    }\n",
    "})\n",
    "pprint(sweep_config)\n",
    "\n",
    "# 初始化 sweep controller\n",
    "sweep_id = wandb.sweep(sweep_config, project=config.project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b435ed",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-03T15:50:50.789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309223, 21) (77306, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tkfxqgeg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ReLU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tadd_norm_dropout: 0.6040465555214707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_dropout: 0.8416560693454203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tckpt_path: ./models/tabtransformer_not_balance_2024-06-03_23-50-33.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_initialization: kaiming_normal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tff_dropout: 0.7659779525471568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embed_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: 32-64-16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 3.875949155698934e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_attn_blocks: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptim_type: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tproject_name: pytorch-tabular-tabtransformer\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.2556295391881365e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/s1751118/1751118/myMusicReSystem/wandb/run-20240603_235054-tkfxqgeg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/runs/tkfxqgeg' target=\"_blank\">rose-sweep-1</a></strong> to <a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/sweeps/gawoh8t1' target=\"_blank\">https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/sweeps/gawoh8t1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer' target=\"_blank\">https://wandb.ai/youmeng/pytorch-tabular-tabtransformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/sweeps/gawoh8t1' target=\"_blank\">https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/sweeps/gawoh8t1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/runs/tkfxqgeg' target=\"_blank\">https://wandb.ai/youmeng/pytorch-tabular-tabtransformer/runs/tkfxqgeg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b233eab1739045f5a7758c31c52550e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ TabTransformerBackbone │  271 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding2dLayer       │  118 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead             │ 11.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss       │      0 │\n",
       "└───┴──────────────────┴────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabTransformerBackbone │  271 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding2dLayer       │  118 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead             │ 11.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss       │      0 │\n",
       "└───┴──────────────────┴────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 401 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 401 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 401 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 401 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'input_embed_dim' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'embedding_initialization' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_heads' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_attn_blocks' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'attn_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'add_norm_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ff_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'project_name' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c052af963e44545a271f6e8c1be5871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "data = pd.concat([X, y], axis = 1)\n",
    "\n",
    "target_col = \"labels\"\n",
    "categorical_cols = categorical_features\n",
    "continuous_cols = numerical_features\n",
    "\n",
    "# Split the combined dataset back into train, validation, and test sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(train.shape, val.shape)\n",
    "def train_once():\n",
    "    data_config = DataConfig(\n",
    "        target=[target_col],\n",
    "        continuous_cols=continuous_cols,\n",
    "        categorical_cols=categorical_cols,\n",
    "    )\n",
    "    experiment_config = ExperimentConfig(\n",
    "        project_name=config.project_name,\n",
    "        run_name=f\"TabTransformer_{current_time}\",\n",
    "        exp_watch=\"gradients\",\n",
    "        log_target=\"wandb\",\n",
    "    )\n",
    "    linear_head_config = LinearHeadConfig(\n",
    "        layers=config.layers, \n",
    "        activation=config.activation,\n",
    "        dropout=0.3,\n",
    "        use_batch_norm=True,\n",
    "        initialization=config.initialization\n",
    "    )\n",
    "    model_config = TabTransformerConfig(\n",
    "        task=\"classification\",\n",
    "        input_embed_dim=config.input_embed_dim,\n",
    "        num_heads=config.num_heads,\n",
    "        num_attn_blocks=config.num_attn_blocks,\n",
    "        learning_rate=config.lr,\n",
    "        metrics=[\"accuracy\"],\n",
    "        attn_dropout=0.3,\n",
    "        add_norm_dropout=0.3,\n",
    "        ff_dropout=0.3,\n",
    "        batch_norm_continuous_input=True,\n",
    "#         embedding_initialization = config.embedding_initialization,\n",
    "        head_config = asdict(linear_head_config)\n",
    "    )\n",
    "    trainer_config = TrainerConfig(\n",
    "        auto_lr_find=True,\n",
    "        batch_size=config.batch_size,\n",
    "        max_epochs=config.epochs,\n",
    "        accelerator='gpu',\n",
    "        devices=-1,\n",
    "        load_best=True, \n",
    "        track_grad_norm =-1,\n",
    "        min_epochs = 20,\n",
    "        early_stopping=None,\n",
    "   \n",
    "    )\n",
    "    optim_config = OptimizerConfig(\n",
    "        optimizer = config.optim_type,\n",
    "    )\n",
    "    # Initialize and train the model\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optim_config,\n",
    "        trainer_config=trainer_config,\n",
    "        experiment_config=experiment_config,\n",
    "        verbose=False,\n",
    "        suppress_lightning_logger=True,\n",
    "    )\n",
    "    with wandb.init() as run:\n",
    "        tabular_model.fit(train=train, validation=val)\n",
    "        # Evaluate the model\n",
    "        result = tabular_model.evaluate(test)\n",
    "        print(result)\n",
    "        wandb.save(f\"./models/tabtransformer_{current_time}.pth\")\n",
    "\n",
    "# 该agent 随机搜索5次\n",
    "wandb.agent(sweep_id, train_once, count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febffd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T04:57:09.360960Z",
     "start_time": "2024-05-23T04:57:09.360944Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
