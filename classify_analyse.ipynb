{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474f39a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:40.836145Z",
     "start_time": "2024-05-15T02:40:39.298353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303682 entries, 0 to 303681\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   score          303682 non-null  float64\n",
      " 1   hashtag        303682 non-null  object \n",
      " 2   lang           303682 non-null  object \n",
      " 3   tweet_lang     303682 non-null  object \n",
      " 4   time_zone      303682 non-null  object \n",
      " 5   month          303682 non-null  int64  \n",
      " 6   hours          303682 non-null  int64  \n",
      " 7   track_id       303682 non-null  object \n",
      " 8   season         303682 non-null  int64  \n",
      " 9   day_time       303682 non-null  object \n",
      " 10  weekday_index  303682 non-null  int64  \n",
      " 11  weekend        303682 non-null  bool   \n",
      "dtypes: bool(1), float64(1), int64(4), object(6)\n",
      "memory usage: 25.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('./data/classify_data.csv')\n",
    "# df.drop(['season', 'day_time', 'weekday_index', 'weekend'], axis = 1, inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f86b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:44.182353Z",
     "start_time": "2024-05-15T02:40:44.143978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25491 entries, 0 to 25490\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   track_id  25491 non-null  object\n",
      " 1   labels    25491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 398.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# track_to_label = pd.read_csv('./data/track_to_labels_dbscan.csv')\n",
    "track_to_label = pd.read_csv('./data/track_to_labels_kmeans_5.csv')\n",
    "track_to_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea16248a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:46.057454Z",
     "start_time": "2024-05-15T02:40:45.836253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>month</th>\n",
       "      <th>hours</th>\n",
       "      <th>track_id</th>\n",
       "      <th>season</th>\n",
       "      <th>day_time</th>\n",
       "      <th>weekday_index</th>\n",
       "      <th>weekend</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>kiss92</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3Px454rzMHtIRc9R04QSlB</td>\n",
       "      <td>0</td>\n",
       "      <td>Wee hours(00:00 - 6:00)</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>kiss92</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5eaD4UEbmcXZe0buNHOM64</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning(6:00 - 12:00)</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>kiss92</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>75VOiyc0bT0VkFFQuKakgE</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning(6:00 - 12:00)</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "      <td>kiss92</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0Dy1Q2uUKII4asOHvexBn9</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning(6:00 - 12:00)</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>kiss92</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>777VRhgQZ1L2c0RJnLlNI9</td>\n",
       "      <td>0</td>\n",
       "      <td>Morning(6:00 - 12:00)</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score hashtag lang tweet_lang time_zone  month  hours  \\\n",
       "0    0.8  kiss92   en         en   Beijing      1      5   \n",
       "1    0.8  kiss92   en         en   Beijing      1      6   \n",
       "2    0.8  kiss92   en         en   Beijing      1      6   \n",
       "3    0.8  kiss92   en         en   Beijing      1      6   \n",
       "4    0.8  kiss92   en         en   Beijing      1      6   \n",
       "\n",
       "                 track_id  season                 day_time  weekday_index  \\\n",
       "0  3Px454rzMHtIRc9R04QSlB       0  Wee hours(00:00 - 6:00)              2   \n",
       "1  5eaD4UEbmcXZe0buNHOM64       0    Morning(6:00 - 12:00)              2   \n",
       "2  75VOiyc0bT0VkFFQuKakgE       0    Morning(6:00 - 12:00)              2   \n",
       "3  0Dy1Q2uUKII4asOHvexBn9       0    Morning(6:00 - 12:00)              2   \n",
       "4  777VRhgQZ1L2c0RJnLlNI9       0    Morning(6:00 - 12:00)              2   \n",
       "\n",
       "   weekend  labels  \n",
       "0    False       1  \n",
       "1    False       3  \n",
       "2    False       3  \n",
       "3    False       1  \n",
       "4    False       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(track_to_label, on='track_id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd53fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:47.950857Z",
     "start_time": "2024-05-15T02:40:47.762667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    102766\n",
       "1     83196\n",
       "0     62536\n",
       "4     29786\n",
       "2     25398\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0219d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T05:23:47.738876Z",
     "start_time": "2024-05-14T05:23:47.705075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    102766\n",
       "1     83196\n",
       "0     62536\n",
       "4     29786\n",
       "2     25398\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除离群点\n",
    "df = df[df['labels'] != -1]\n",
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f11627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:52.976089Z",
     "start_time": "2024-05-15T02:40:50.619636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mood  mood_label\n",
      "0       happiness           3\n",
      "1       happiness           3\n",
      "2       happiness           3\n",
      "3       happiness           3\n",
      "4       happiness           3\n",
      "...           ...         ...\n",
      "303677  happiness           3\n",
      "303678    disgust           0\n",
      "303679    sadness           1\n",
      "303680    sadness           1\n",
      "303681    sadness           1\n",
      "\n",
      "[303682 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 303682 entries, 0 to 303681\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   score          303682 non-null  float64 \n",
      " 1   hashtag        303682 non-null  object  \n",
      " 2   lang           303682 non-null  object  \n",
      " 3   tweet_lang     303682 non-null  object  \n",
      " 4   time_zone      303682 non-null  object  \n",
      " 5   month          303682 non-null  int64   \n",
      " 6   hours          303682 non-null  int64   \n",
      " 7   season         303682 non-null  int64   \n",
      " 8   day_time       303682 non-null  object  \n",
      " 9   weekday_index  303682 non-null  int64   \n",
      " 10  weekend        303682 non-null  bool    \n",
      " 11  labels         303682 non-null  int64   \n",
      " 12  score_2        303682 non-null  float64 \n",
      " 13  score_3        303682 non-null  float64 \n",
      " 14  mood           303682 non-null  category\n",
      " 15  mood_label     303682 non-null  int8    \n",
      " 16  happy          303682 non-null  category\n",
      "dtypes: bool(1), category(2), float64(3), int64(5), int8(1), object(5)\n",
      "memory usage: 33.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# # 创建交叉组合特征\n",
    "# df['month_day_time'] = df['month'].astype(str) + '_' + df['day_time']\n",
    "# df['day_time_hours'] = df['day_time'] + '_' + df['hours'].astype(str)\n",
    "\n",
    "# 对分数score取平方、3次方\n",
    "df['score_2'] = df['score'] ** 2\n",
    "df['score_3'] = df['score'] ** 3\n",
    "\n",
    "# 对情绪分数score进行分箱操作\n",
    "labels = ['disgust', 'sadness', 'neutral', 'happiness', 'surprise']\n",
    "bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "df['mood'] = pd.cut(df['score'], labels=labels, bins = bins, include_lowest=True)\n",
    "df['mood'] = df['mood'].astype('category')\n",
    "\n",
    "df['mood_label'] = df['mood'].cat.codes\n",
    "print(df[['mood', 'mood_label']])\n",
    "\n",
    "bins = [0.0, 0.5, 1.0]\n",
    "df['happy'] = pd.cut(df['score'], labels=[0, 1], bins = bins, include_lowest=True)\n",
    "\n",
    "if (df['labels'] >= 2).sum() > 0:\n",
    "    df.to_csv('./data/final_classify_data_5.csv', index = False)\n",
    "else:\n",
    "    df.to_csv('./data/final_classify_data_2.csv', index = False)\n",
    "\n",
    "track_id = df.drop(['track_id'], inplace = True,  axis = 1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e84e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:56.340778Z",
     "start_time": "2024-05-15T02:40:56.317579Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['mood'], inplace = True,  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19ff785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:40:58.613538Z",
     "start_time": "2024-05-15T02:40:57.768538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 303682 entries, 0 to 303681\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   score          303682 non-null  float64 \n",
      " 1   hashtag        303682 non-null  int64   \n",
      " 2   lang           303682 non-null  int64   \n",
      " 3   tweet_lang     303682 non-null  int64   \n",
      " 4   time_zone      303682 non-null  int64   \n",
      " 5   month          303682 non-null  int64   \n",
      " 6   hours          303682 non-null  int64   \n",
      " 7   season         303682 non-null  int64   \n",
      " 8   day_time       303682 non-null  int64   \n",
      " 9   weekday_index  303682 non-null  int64   \n",
      " 10  weekend        303682 non-null  bool    \n",
      " 11  labels         303682 non-null  int64   \n",
      " 12  score_2        303682 non-null  float64 \n",
      " 13  score_3        303682 non-null  float64 \n",
      " 14  mood_label     303682 non-null  int8    \n",
      " 15  happy          303682 non-null  category\n",
      "dtypes: bool(1), category(1), float64(3), int64(10), int8(1)\n",
      "memory usage: 33.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 对几个类别特别多的列采用二进制编码\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # 二进制编码\n",
    "# columns = ['hashtag', 'tweet_lang', 'time_zone', 'lang', 'month_day_time', 'day_time_hours']\n",
    "\n",
    "# 不交叉组合\n",
    "columns = ['hashtag', 'tweet_lang', 'time_zone', 'lang']\n",
    "\n",
    "# # 特征衍生\n",
    "columns += ['day_time']\n",
    "for column in columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[column] = encoder.fit_transform(df[column])\n",
    "    \n",
    "print(df.info())\n",
    "# 查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6968424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:41:00.150454Z",
     "start_time": "2024-05-15T02:41:00.079800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 303682 entries, 0 to 303681\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   score          303682 non-null  float64 \n",
      " 1   hashtag        303682 non-null  int64   \n",
      " 2   lang           303682 non-null  int64   \n",
      " 3   tweet_lang     303682 non-null  int64   \n",
      " 4   time_zone      303682 non-null  int64   \n",
      " 5   month          303682 non-null  int64   \n",
      " 6   hours          303682 non-null  int64   \n",
      " 7   season         303682 non-null  int64   \n",
      " 8   day_time       303682 non-null  int64   \n",
      " 9   weekday_index  303682 non-null  int64   \n",
      " 10  weekend        303682 non-null  bool    \n",
      " 11  score_2        303682 non-null  float64 \n",
      " 12  score_3        303682 non-null  float64 \n",
      " 13  mood_label     303682 non-null  int8    \n",
      " 14  happy          303682 non-null  category\n",
      "dtypes: bool(1), category(1), float64(3), int64(9), int8(1)\n",
      "memory usage: 31.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(['labels'], axis = 1)\n",
    "y = df['labels']\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6460eb45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:41:02.080319Z",
     "start_time": "2024-05-15T02:41:01.698831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82754784 -0.36175517 -0.55244037 ...  1.05782618  0.49313616\n",
      "   0.56103495]\n",
      " [ 0.82754784 -0.36175517 -0.55244037 ...  1.05782618  0.49313616\n",
      "   0.56103495]\n",
      " [ 0.82754784 -0.36175517 -0.55244037 ...  1.05782618  0.49313616\n",
      "   0.56103495]\n",
      " ...\n",
      " [-1.44799913 -1.6336019  -0.55244037 ... -1.53373656 -1.30759102\n",
      "  -1.78242015]\n",
      " [-1.44799913 -1.77604874 -0.55244037 ... -1.53373656 -1.30759102\n",
      "  -1.78242015]\n",
      " [-1.44799913 -1.57933644 -0.55244037 ... -1.53373656 -1.30759102\n",
      "  -1.78242015]] \n",
      " [1 3 3 ... 0 0 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = np.array(y)\n",
    "print(X, '\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fb686",
   "metadata": {},
   "source": [
    "### 分类\n",
    "#### 常用机器学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b39304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:49:24.093221Z",
     "start_time": "2024-05-14T03:48:08.273803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.971222975566074, 1: 0.7300399057647002, 2: 2.3913851484368847, 3: 0.5910164840511454, 4: 2.039092190962197}\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为2的准确率为0.3380970413421802\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为3的准确率为0.3380970413421802\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为4的准确率为0.3380970413421802\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为5的准确率为0.3380970413421802\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为6的准确率为0.3380970413421802\n",
      "LogisticRegression y_pred 0 的个数为 为0, 1的个数为0,2的个数为：0, 3的个数为:60737, 4的个数为：0\n",
      "LogisticRegression 降维为7的准确率为0.3380970413421802\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为30, 1的个数为5300,2的个数为：0, 3的个数为:55407, 4的个数为：0\n",
      "LightGBM 降维为2的准确率为0.34828852264682153\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为57, 1的个数为4951,2的个数为：0, 3的个数为:55726, 4的个数为：3\n",
      "LightGBM 降维为3的准确率为0.35041243393648025\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为133, 1的个数为6547,2的个数为：0, 3的个数为:54050, 4的个数为：7\n",
      "LightGBM 降维为4的准确率为0.35393582165730936\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为120, 1的个数为6106,2的个数为：0, 3的个数为:54497, 4的个数为：14\n",
      "LightGBM 降维为5的准确率为0.35413339480053346\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为260, 1的个数为5086,2的个数为：15, 3的个数为:55333, 4的个数为：43\n",
      "LightGBM 降维为6的准确率为0.3596983716680113\n",
      "[LightGBM] [Info] Total Bins 1785\n",
      "[LightGBM] [Info] Number of data points in the train set: 242945, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score -1.578614\n",
      "[LightGBM] [Info] Start training from score -1.294972\n",
      "[LightGBM] [Info] Start training from score -2.484384\n",
      "[LightGBM] [Info] Start training from score -1.083303\n",
      "[LightGBM] [Info] Start training from score -2.322981\n",
      "LightGBM y_pred 0 的个数为 为347, 1的个数为5097,2的个数为：67, 3的个数为:55205, 4的个数为：21\n",
      "LightGBM 降维为7的准确率为0.3617893541004659\n",
      "RandomForest y_pred 0 的个数为 为9934, 1的个数为17633,2的个数为：2288, 3的个数为:28138, 4的个数为：2744\n",
      "RandomForest 降维为2的准确率为0.31157284686434955\n",
      "RandomForest y_pred 0 的个数为 为9933, 1的个数为17600,2的个数为：2245, 3的个数为:28266, 4的个数为：2693\n",
      "RandomForest 降维为3的准确率为0.31443765744109853\n",
      "RandomForest y_pred 0 的个数为 为9931, 1的个数为17628,2的个数为：2195, 3的个数为:28355, 4的个数为：2628\n",
      "RandomForest 降维为4的准确率为0.31529380772840276\n",
      "RandomForest y_pred 0 的个数为 为9860, 1的个数为17592,2的个数为：2166, 3的个数为:28503, 4的个数为：2616\n",
      "RandomForest 降维为5的准确率为0.3165615687307572\n",
      "RandomForest y_pred 0 的个数为 为9995, 1的个数为17522,2的个数为：2208, 3的个数为:28341, 4的个数为：2671\n",
      "RandomForest 降维为6的准确率为0.3226698717421012\n",
      "RandomForest y_pred 0 的个数为 为9965, 1的个数为17493,2的个数为：2259, 3的个数为:28319, 4的个数为：2701\n",
      "RandomForest 降维为7的准确率为0.32522185817541205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight    \n",
    "\n",
    "# 降维\n",
    "n_components = np.arange(2, 8)\n",
    "\n",
    "# 假设你有五个类别，其中某些类别的样本量远少于其他\n",
    "classes = np.array([0, 1, 2, 3, 4])\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(weight_dict)\n",
    "\n",
    "# # 定义模型\n",
    "# models = {\n",
    "#     'LogisticRegression': LogisticRegression(C=0.1, max_iter=5000, class_weight=weight_dict),\n",
    "#     'LightGBM': lgb.LGBMClassifier(n_estimators=10, random_state=42, force_row_wise=True,  class_weight=weight_dict),\n",
    "#     'RandomForest': RandomForestClassifier(n_estimators=10, random_state=42,  class_weight=weight_dict)\n",
    "# }\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(C=0.1, max_iter=5000),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=10, random_state=42, force_row_wise=True),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "for name, model in models.items():\n",
    "    for n_component in n_components:\n",
    "        X_pca = PCA(n_components = n_component).fit_transform(X, y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f'{name} y_pred 0 的个数为 为{(y_pred == 0).sum()}, 1的个数为{(y_pred == 1).sum()},2的个数为：{(y_pred == 2).sum()}, 3的个数为:{(y_pred == 3).sum()}, 4的个数为：{(y_pred==4).sum()}')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'{name} 降维为{n_component}的准确率为{accuracy}')\n",
    "        if name not in scores:\n",
    "            scores[name] = []\n",
    "        scores[name].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7551a6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.341Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 创建图和轴\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 循环遍历scores字典中的每个模型，绘制其准确率折线图\n",
    "for model_name, accuracies in scores.items():\n",
    "    ax.plot(n_components, accuracies, label=model_name)\n",
    "\n",
    "# 设置图例\n",
    "ax.legend()\n",
    "\n",
    "# 添加标题和轴标签\n",
    "ax.set_title('Model Accuracy by Number of PCA Components')\n",
    "ax.set_xlabel('Number of PCA Components')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c6e96",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# 因此降为7维进行交叉验证\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_pca = PCA(n_components = 9).fit_transform(X_resampled_norm_and_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64b3ca",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.343Z"
    }
   },
   "outputs": [],
   "source": [
    "# LDA降维\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "X_lda = LDA(n_components = 3).fit_transform(X_resampled_norm_and_one, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe11218",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.344Z"
    }
   },
   "outputs": [],
   "source": [
    "X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8e568",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.345Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "# 定义模型\n",
    "\n",
    "# # 有五个类别，其中某些类别的样本量远少于其他\n",
    "# classes = np.array([0, 1, 2, 3, 4])\n",
    "# class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "# weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "# print(weight_dict)\n",
    "\n",
    "# models = {\n",
    "#     'LogisticRegression': LogisticRegression(C=0.1, max_iter=10000, class_weight=weight_dict),\n",
    "#     'LightGBM': lgb.LGBMClassifier(n_estimators=10, random_state=42, force_row_wise=True,  class_weight=weight_dict),\n",
    "#     'RandomForest': RandomForestClassifier(n_estimators=10, random_state=42,  class_weight=weight_dict)\n",
    "# }\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(C=0.1, max_iter=10000),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=10, random_state=42, force_row_wise=True),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "}\n",
    "\n",
    "## 去除噪声，平衡样本，32 33 （未衍生）\n",
    "## 去除噪声，未平衡样本，41、43、43 （这里预测值有偏向）\n",
    "\n",
    "# 定义评估指标\n",
    "num_classes = len(set(y))\n",
    "print(num_classes)\n",
    "\n",
    "scoring = []\n",
    "if num_classes == 2:\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "elif num_classes > 2:\n",
    "    scoring = ['accuracy', 'f1_micro', 'f1_macro', 'f1_weighted']\n",
    "else:\n",
    "    print(f'Error num_classes of {num_classes}')\n",
    "\n",
    "# 使用Stratified K-Fold进行交叉验证\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 训练模型并评估\n",
    "results = {name: [] for name in models}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    start_time = time.time()\n",
    "    for score_name in scoring:\n",
    "        score = cross_val_score(model, X_resampled_norm_and_one, y, scoring=score_name, cv=cv, n_jobs=-1)\n",
    "        results[model_name].append((score.mean(), score.std()))\n",
    "    end_time = time.time()\n",
    "    print(f'{model_name}运行时间为：{end_time - start_time}')\n",
    "\n",
    "# 输出结果\n",
    "for model_name, model_scores in results.items():\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    for i, score_name in enumerate(scoring):\n",
    "        mean, std = model_scores[i]\n",
    "        print(f\"{score_name}: {100 * mean:.2f}±{100 * std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710577a9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-06T07:43:47.346Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 参数网格\n",
    "param_grid_lr = {\n",
    "    'C': [1],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# 创建模型\n",
    "logistic_model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search_lr = GridSearchCV(estimator=logistic_model, param_grid=param_grid_lr, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# 加载数据\n",
    "grid_search_lr.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 获取最佳参数和最佳分数\n",
    "best_parameters = grid_search_lr.best_params_\n",
    "best_score = grid_search_lr.best_score_\n",
    "\n",
    "# 打印结果\n",
    "print(\"Best parameters:\", best_parameters)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8a374c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:35:43.276571Z",
     "start_time": "2024-05-09T10:30:52.311232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=  33.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=  54.2s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=log2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=  44.2s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=  10.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100; total time=  20.9s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=  27.4s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=  34.7s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=log2, min_samples_split=10, n_estimators=50; total time=  11.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=  20.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=  23.4s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_split=10, n_estimators=200; total time=  44.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=  47.5s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=sqrt, min_samples_split=10, n_estimators=50; total time=  17.2s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=log2, min_samples_split=5, n_estimators=100; total time=  24.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=  41.6s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50; total time=  14.9s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_split=5, n_estimators=200; total time=  57.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100; total time=  20.8s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=200; total time=  57.5s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=log2, min_samples_split=5, n_estimators=50; total time=  16.7s\n",
      "[CV] END criterion=gini, max_depth=40, max_features=log2, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=  15.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_split=10, n_estimators=200; total time=  40.1s\n",
      "[CV] END criterion=entropy, max_depth=40, max_features=sqrt, min_samples_split=5, n_estimators=50; total time=  18.1s\n",
      "[CV] END criterion=entropy, max_depth=40, max_features=sqrt, min_samples_split=10, n_estimators=200; total time=  56.4s\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best score: 0.6329888804636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# 参数网格\n",
    "param_grid_lr = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 40],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# 创建模型\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search_lr = GridSearchCV(estimator=rf, param_grid=param_grid_lr, cv=2, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# 加载数据\n",
    "grid_search_lr.fit(X, y)\n",
    "\n",
    "# 获取最佳参数和最佳分数\n",
    "best_parameters = grid_search_lr.best_params_\n",
    "best_score = grid_search_lr.best_score_\n",
    "\n",
    "# 打印结果\n",
    "print(\"Best parameters:\", best_parameters)\n",
    "print(\"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10341db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:47:58.450898Z",
     "start_time": "2024-05-15T08:47:58.298519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9712, 0.7300, 2.3914, 0.5910, 2.0391], device='cuda:0')\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_classes, dim_feedforward=128, num_layers=3):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding = nn.Linear(input_dim, dim_feedforward)\n",
    "        \n",
    "        # 添加 Batch Normalization 层\n",
    "        self.batch_norm = nn.BatchNorm1d(dim_feedforward)\n",
    "        \n",
    "        # 初始化 Transformer 编码器层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_feedforward, nhead=num_heads)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Dropout 层\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(dim_feedforward, num_classes)\n",
    "        \n",
    "        # ReLU 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, input_dim)\n",
    "        src = self.embedding(src)  # (batch_size, dim_feedforward)\n",
    "        \n",
    "        # 应用批归一化\n",
    "#         src = self.batch_norm(src)\n",
    "        \n",
    "        # 应用 ReLU 激活函数\n",
    "        src = self.relu(src)\n",
    "        \n",
    "        src = src.unsqueeze(1)  # (batch_size, 1, dim_feedforward) - Transformer expects seq_len, batch, dim\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.squeeze(1)  # (batch_size, dim_feedforward)\n",
    "        \n",
    "        # 应用 Dropout\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.output_layer(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "model = TransformerModel(input_dim=X.shape[1], num_heads=2, num_classes= len(set(y))).to(device)\n",
    "# 有五个类别，其中某些类别的样本量远少于其他\n",
    "classes = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# classes = np.array([0, 1])\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()  # 如果你在使用GPU\n",
    "print(class_weights)\n",
    "\n",
    "# if (y > 2).sum() == 0:\n",
    "#     criterion = nn.BCELoss().to(device)\n",
    "# else:\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "print(criterion)\n",
    "\n",
    "# lr = 0.0001 准确率0.64\n",
    "# lr = 0.00005, 65.03\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34d6fa2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T09:27:23.069590Z",
     "start_time": "2024-05-15T08:48:00.440667Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "训练集预测为0的样本数为：14093\n",
      "训练集预测为1的样本数为：57440\n",
      "训练集预测为2的样本数为：337\n",
      "训练集预测为3的样本数为：170636\n",
      "训练集预测为4的样本数为：439\n",
      "Average Training Loss: 1.5092844007264228, Accuracy: 32.26%\n",
      "测试集预测为0的样本数为：0\n",
      "测试集预测为1的样本数为：6639\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：54098\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4756646667925417, Accuracy: 35.08%\n",
      "Epoch 2\n",
      "训练集预测为0的样本数为：2739\n",
      "训练集预测为1的样本数为：51515\n",
      "训练集预测为2的样本数为：0\n",
      "训练集预测为3的样本数为：188691\n",
      "训练集预测为4的样本数为：0\n",
      "Average Training Loss: 1.4852435846000922, Accuracy: 34.06%\n",
      "测试集预测为0的样本数为：0\n",
      "测试集预测为1的样本数为：5952\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：54785\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4717862868447125, Accuracy: 35.17%\n",
      "Epoch 3\n",
      "训练集预测为0的样本数为：1533\n",
      "训练集预测为1的样本数为：49371\n",
      "训练集预测为2的样本数为：1\n",
      "训练集预测为3的样本数为：192039\n",
      "训练集预测为4的样本数为：1\n",
      "Average Training Loss: 1.4804380578076621, Accuracy: 34.52%\n",
      "测试集预测为0的样本数为：5\n",
      "测试集预测为1的样本数为：6419\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：54313\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4701789453068552, Accuracy: 35.20%\n",
      "Epoch 4\n",
      "训练集预测为0的样本数为：1013\n",
      "训练集预测为1的样本数为：46972\n",
      "训练集预测为2的样本数为：1\n",
      "训练集预测为3的样本数为：194958\n",
      "训练集预测为4的样本数为：1\n",
      "Average Training Loss: 1.4778120377923163, Accuracy: 34.77%\n",
      "测试集预测为0的样本数为：1\n",
      "测试集预测为1的样本数为：7374\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：53362\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.467836833301502, Accuracy: 35.25%\n",
      "Epoch 5\n",
      "训练集预测为0的样本数为：812\n",
      "训练集预测为1的样本数为：43318\n",
      "训练集预测为2的样本数为：7\n",
      "训练集预测为3的样本数为：198807\n",
      "训练集预测为4的样本数为：1\n",
      "Average Training Loss: 1.4754693547083928, Accuracy: 34.93%\n",
      "测试集预测为0的样本数为：29\n",
      "测试集预测为1的样本数为：7864\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：52844\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4654190428888503, Accuracy: 35.38%\n",
      "Epoch 6\n",
      "训练集预测为0的样本数为：1084\n",
      "训练集预测为1的样本数为：40185\n",
      "训练集预测为2的样本数为：36\n",
      "训练集预测为3的样本数为：201639\n",
      "训练集预测为4的样本数为：1\n",
      "Average Training Loss: 1.4725813850903722, Accuracy: 34.96%\n",
      "测试集预测为0的样本数为：207\n",
      "测试集预测为1的样本数为：9846\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：50684\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4637243992532787, Accuracy: 35.42%\n",
      "Epoch 7\n",
      "训练集预测为0的样本数为：1382\n",
      "训练集预测为1的样本数为：38518\n",
      "训练集预测为2的样本数为：64\n",
      "训练集预测为3的样本数为：202979\n",
      "训练集预测为4的样本数为：2\n",
      "Average Training Loss: 1.47056940806708, Accuracy: 35.09%\n",
      "测试集预测为0的样本数为：108\n",
      "测试集预测为1的样本数为：5980\n",
      "测试集预测为2的样本数为：0\n",
      "测试集预测为3的样本数为：54649\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4617320173599018, Accuracy: 35.42%\n",
      "Epoch 8\n",
      "训练集预测为0的样本数为：1585\n",
      "训练集预测为1的样本数为：36531\n",
      "训练集预测为2的样本数为：137\n",
      "训练集预测为3的样本数为：204691\n",
      "训练集预测为4的样本数为：1\n",
      "Average Training Loss: 1.468517117375962, Accuracy: 35.15%\n",
      "测试集预测为0的样本数为：323\n",
      "测试集预测为1的样本数为：7703\n",
      "测试集预测为2的样本数为：7\n",
      "测试集预测为3的样本数为：52704\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4593045818234445, Accuracy: 35.56%\n",
      "Epoch 9\n",
      "训练集预测为0的样本数为：2161\n",
      "训练集预测为1的样本数为：35254\n",
      "训练集预测为2的样本数为：228\n",
      "训练集预测为3的样本数为：205299\n",
      "训练集预测为4的样本数为：3\n",
      "Average Training Loss: 1.4657220021861668, Accuracy: 35.19%\n",
      "测试集预测为0的样本数为：487\n",
      "测试集预测为1的样本数为：7757\n",
      "测试集预测为2的样本数为：14\n",
      "测试集预测为3的样本数为：52479\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4566558351511703, Accuracy: 35.63%\n",
      "Epoch 10\n",
      "训练集预测为0的样本数为：3131\n",
      "训练集预测为1的样本数为：32209\n",
      "训练集预测为2的样本数为：412\n",
      "训练集预测为3的样本数为：207187\n",
      "训练集预测为4的样本数为：6\n",
      "Average Training Loss: 1.4626532369304925, Accuracy: 35.36%\n",
      "测试集预测为0的样本数为：521\n",
      "测试集预测为1的样本数为：7464\n",
      "测试集预测为2的样本数为：51\n",
      "测试集预测为3的样本数为：52701\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4534579723869392, Accuracy: 35.70%\n",
      "Epoch 11\n",
      "训练集预测为0的样本数为：3193\n",
      "训练集预测为1的样本数为：29374\n",
      "训练集预测为2的样本数为：636\n",
      "训练集预测为3的样本数为：209736\n",
      "训练集预测为4的样本数为：6\n",
      "Average Training Loss: 1.4597491247921173, Accuracy: 35.46%\n",
      "测试集预测为0的样本数为：294\n",
      "测试集预测为1的样本数为：7511\n",
      "测试集预测为2的样本数为：168\n",
      "测试集预测为3的样本数为：52764\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4518458708265445, Accuracy: 35.80%\n",
      "Epoch 12\n",
      "训练集预测为0的样本数为：3214\n",
      "训练集预测为1的样本数为：28072\n",
      "训练集预测为2的样本数为：741\n",
      "训练集预测为3的样本数为：210898\n",
      "训练集预测为4的样本数为：20\n",
      "Average Training Loss: 1.458188622926953, Accuracy: 35.54%\n",
      "测试集预测为0的样本数为：218\n",
      "测试集预测为1的样本数为：6060\n",
      "测试集预测为2的样本数为：236\n",
      "测试集预测为3的样本数为：54223\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4505883941780962, Accuracy: 35.71%\n",
      "Epoch 13\n",
      "训练集预测为0的样本数为：3098\n",
      "训练集预测为1的样本数为：26871\n",
      "训练集预测为2的样本数为：833\n",
      "训练集预测为3的样本数为：212120\n",
      "训练集预测为4的样本数为：23\n",
      "Average Training Loss: 1.4573529454287406, Accuracy: 35.50%\n",
      "测试集预测为0的样本数为：586\n",
      "测试集预测为1的样本数为：5220\n",
      "测试集预测为2的样本数为：199\n",
      "测试集预测为3的样本数为：54732\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4498905897642702, Accuracy: 35.79%\n",
      "Epoch 14\n",
      "训练集预测为0的样本数为：3254\n",
      "训练集预测为1的样本数为：27613\n",
      "训练集预测为2的样本数为：896\n",
      "训练集预测为3的样本数为：211168\n",
      "训练集预测为4的样本数为：14\n",
      "Average Training Loss: 1.4560076659114782, Accuracy: 35.61%\n",
      "测试集预测为0的样本数为：1232\n",
      "测试集预测为1的样本数为：7321\n",
      "测试集预测为2的样本数为：158\n",
      "测试集预测为3的样本数为：52026\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.448976694878432, Accuracy: 35.95%\n",
      "Epoch 15\n",
      "训练集预测为0的样本数为：3530\n",
      "训练集预测为1的样本数为：27237\n",
      "训练集预测为2的样本数为：876\n",
      "训练集预测为3的样本数为：211285\n",
      "训练集预测为4的样本数为：17\n",
      "Average Training Loss: 1.4551837008476383, Accuracy: 35.67%\n",
      "测试集预测为0的样本数为：672\n",
      "测试集预测为1的样本数为：6436\n",
      "测试集预测为2的样本数为：91\n",
      "测试集预测为3的样本数为：53538\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4480295926410942, Accuracy: 35.92%\n",
      "Epoch 16\n",
      "训练集预测为0的样本数为：3555\n",
      "训练集预测为1的样本数为：26845\n",
      "训练集预测为2的样本数为：786\n",
      "训练集预测为3的样本数为：211726\n",
      "训练集预测为4的样本数为：33\n",
      "Average Training Loss: 1.454790226009293, Accuracy: 35.69%\n",
      "测试集预测为0的样本数为：245\n",
      "测试集预测为1的样本数为：5524\n",
      "测试集预测为2的样本数为：309\n",
      "测试集预测为3的样本数为：54659\n",
      "测试集预测为4的样本数为：0\n",
      "Test Loss: 1.4480526067508779, Accuracy: 35.92%\n",
      "Epoch 17\n",
      "训练集预测为0的样本数为：3624\n",
      "训练集预测为1的样本数为：27168\n",
      "训练集预测为2的样本数为：962\n",
      "训练集预测为3的样本数为：211160\n",
      "训练集预测为4的样本数为：31\n",
      "Average Training Loss: 1.4534394910617197, Accuracy: 35.74%\n",
      "测试集预测为0的样本数为：862\n",
      "测试集预测为1的样本数为：6182\n",
      "测试集预测为2的样本数为：10\n",
      "测试集预测为3的样本数为：53665\n",
      "测试集预测为4的样本数为：18\n",
      "Test Loss: 1.4472818313114513, Accuracy: 35.92%\n",
      "Epoch 18\n",
      "训练集预测为0的样本数为：3686\n",
      "训练集预测为1的样本数为：27900\n",
      "训练集预测为2的样本数为：827\n",
      "训练集预测为3的样本数为：210494\n",
      "训练集预测为4的样本数为：38\n",
      "Average Training Loss: 1.4529952139906555, Accuracy: 35.72%\n",
      "测试集预测为0的样本数为：464\n",
      "测试集预测为1的样本数为：6294\n",
      "测试集预测为2的样本数为：397\n",
      "测试集预测为3的样本数为：53577\n",
      "测试集预测为4的样本数为：5\n",
      "Test Loss: 1.4473983729243467, Accuracy: 35.95%\n",
      "Epoch 19\n",
      "训练集预测为0的样本数为：3432\n",
      "训练集预测为1的样本数为：28026\n",
      "训练集预测为2的样本数为：946\n",
      "训练集预测为3的样本数为：210497\n",
      "训练集预测为4的样本数为：44\n",
      "Average Training Loss: 1.4526022348293404, Accuracy: 35.79%\n",
      "测试集预测为0的样本数为：1068\n",
      "测试集预测为1的样本数为：5737\n",
      "测试集预测为2的样本数为：275\n",
      "测试集预测为3的样本数为：53653\n",
      "测试集预测为4的样本数为：4\n",
      "Test Loss: 1.4467849066032743, Accuracy: 35.93%\n",
      "Epoch 20\n",
      "训练集预测为0的样本数为：3842\n",
      "训练集预测为1的样本数为：26816\n",
      "训练集预测为2的样本数为：955\n",
      "训练集预测为3的样本数为：211285\n",
      "训练集预测为4的样本数为：47\n",
      "Average Training Loss: 1.4517798999168179, Accuracy: 35.77%\n",
      "测试集预测为0的样本数为：767\n",
      "测试集预测为1的样本数为：9109\n",
      "测试集预测为2的样本数为：383\n",
      "测试集预测为3的样本数为：50474\n",
      "测试集预测为4的样本数为：4\n",
      "Test Loss: 1.4472031412531414, Accuracy: 36.00%\n",
      "Epoch 21\n",
      "训练集预测为0的样本数为：4131\n",
      "训练集预测为1的样本数为：28524\n",
      "训练集预测为2的样本数为：893\n",
      "训练集预测为3的样本数为：209340\n",
      "训练集预测为4的样本数为：57\n",
      "Average Training Loss: 1.4514381238064966, Accuracy: 35.81%\n",
      "测试集预测为0的样本数为：570\n",
      "测试集预测为1的样本数为：6828\n",
      "测试集预测为2的样本数为：518\n",
      "测试集预测为3的样本数为：52820\n",
      "测试集预测为4的样本数为：1\n",
      "Test Loss: 1.4452120958346326, Accuracy: 36.05%\n",
      "Epoch 22\n",
      "训练集预测为0的样本数为：3932\n",
      "训练集预测为1的样本数为：28036\n",
      "训练集预测为2的样本数为：880\n",
      "训练集预测为3的样本数为：210029\n",
      "训练集预测为4的样本数为：68\n",
      "Average Training Loss: 1.4505234664095323, Accuracy: 35.80%\n",
      "测试集预测为0的样本数为：1467\n",
      "测试集预测为1的样本数为：4585\n",
      "测试集预测为2的样本数为：330\n",
      "测试集预测为3的样本数为：54332\n",
      "测试集预测为4的样本数为：23\n",
      "Test Loss: 1.4464006457220824, Accuracy: 35.95%\n",
      "Epoch 23\n",
      "训练集预测为0的样本数为：4187\n",
      "训练集预测为1的样本数为：28187\n",
      "训练集预测为2的样本数为：947\n",
      "训练集预测为3的样本数为：209543\n",
      "训练集预测为4的样本数为：81\n",
      "Average Training Loss: 1.450173017112976, Accuracy: 35.89%\n",
      "测试集预测为0的样本数为：658\n",
      "测试集预测为1的样本数为：7223\n",
      "测试集预测为2的样本数为：503\n",
      "测试集预测为3的样本数为：52345\n",
      "测试集预测为4的样本数为：8\n",
      "Test Loss: 1.4457490806393776, Accuracy: 36.02%\n",
      "Epoch 24\n",
      "训练集预测为0的样本数为：4281\n",
      "训练集预测为1的样本数为：28752\n",
      "训练集预测为2的样本数为：951\n",
      "训练集预测为3的样本数为：208876\n",
      "训练集预测为4的样本数为：85\n",
      "Average Training Loss: 1.4498805595012612, Accuracy: 35.88%\n",
      "测试集预测为0的样本数为：1503\n",
      "测试集预测为1的样本数为：7387\n",
      "测试集预测为2的样本数为：124\n",
      "测试集预测为3的样本数为：51718\n",
      "测试集预测为4的样本数为：5\n",
      "Test Loss: 1.4458745795215286, Accuracy: 36.14%\n",
      "Epoch 25\n",
      "训练集预测为0的样本数为：4438\n",
      "训练集预测为1的样本数为：27222\n",
      "训练集预测为2的样本数为：993\n",
      "训练集预测为3的样本数为：210191\n",
      "训练集预测为4的样本数为：101\n",
      "Average Training Loss: 1.4491944395316758, Accuracy: 35.91%\n",
      "测试集预测为0的样本数为：785\n",
      "测试集预测为1的样本数为：7560\n",
      "测试集预测为2的样本数为：244\n",
      "测试集预测为3的样本数为：52134\n",
      "测试集预测为4的样本数为：14\n",
      "Test Loss: 1.4446140650136023, Accuracy: 36.12%\n",
      "Epoch 26\n",
      "训练集预测为0的样本数为：4372\n",
      "训练集预测为1的样本数为：28599\n",
      "训练集预测为2的样本数为：867\n",
      "训练集预测为3的样本数为：208964\n",
      "训练集预测为4的样本数为：143\n",
      "Average Training Loss: 1.449048503764326, Accuracy: 35.97%\n",
      "测试集预测为0的样本数为：1258\n",
      "测试集预测为1的样本数为：7117\n",
      "测试集预测为2的样本数为：185\n",
      "测试集预测为3的样本数为：52165\n",
      "测试集预测为4的样本数为：12\n",
      "Test Loss: 1.4438097014936917, Accuracy: 36.11%\n",
      "Epoch 27\n",
      "训练集预测为0的样本数为：4388\n",
      "训练集预测为1的样本数为：28647\n",
      "训练集预测为2的样本数为：1026\n",
      "训练集预测为3的样本数为：208733\n",
      "训练集预测为4的样本数为：151\n",
      "Average Training Loss: 1.447726893814345, Accuracy: 36.00%\n",
      "测试集预测为0的样本数为：1366\n",
      "测试集预测为1的样本数为：7164\n",
      "测试集预测为2的样本数为：116\n",
      "测试集预测为3的样本数为：51991\n",
      "测试集预测为4的样本数为：100\n",
      "Test Loss: 1.4440639639227186, Accuracy: 36.04%\n",
      "Epoch 28\n",
      "训练集预测为0的样本数为：4756\n",
      "训练集预测为1的样本数为：28257\n",
      "训练集预测为2的样本数为：907\n",
      "训练集预测为3的样本数为：208819\n",
      "训练集预测为4的样本数为：206\n",
      "Average Training Loss: 1.447462739200911, Accuracy: 35.96%\n",
      "测试集预测为0的样本数为：372\n",
      "测试集预测为1的样本数为：6941\n",
      "测试集预测为2的样本数为：306\n",
      "测试集预测为3的样本数为：53081\n",
      "测试集预测为4的样本数为：37\n",
      "Test Loss: 1.4443536876941618, Accuracy: 36.06%\n",
      "Epoch 29\n",
      "训练集预测为0的样本数为：4546\n",
      "训练集预测为1的样本数为：29057\n",
      "训练集预测为2的样本数为：922\n",
      "训练集预测为3的样本数为：208205\n",
      "训练集预测为4的样本数为：215\n",
      "Average Training Loss: 1.4469265247951866, Accuracy: 35.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集预测为0的样本数为：1209\n",
      "测试集预测为1的样本数为：6652\n",
      "测试集预测为2的样本数为：320\n",
      "测试集预测为3的样本数为：52497\n",
      "测试集预测为4的样本数为：59\n",
      "Test Loss: 1.4436515811369757, Accuracy: 36.10%\n",
      "Epoch 30\n",
      "训练集预测为0的样本数为：4834\n",
      "训练集预测为1的样本数为：28804\n",
      "训练集预测为2的样本数为：937\n",
      "训练集预测为3的样本数为：208121\n",
      "训练集预测为4的样本数为：249\n",
      "Average Training Loss: 1.4470101402444235, Accuracy: 36.00%\n",
      "测试集预测为0的样本数为：2009\n",
      "测试集预测为1的样本数为：8088\n",
      "测试集预测为2的样本数为：313\n",
      "测试集预测为3的样本数为：50264\n",
      "测试集预测为4的样本数为：63\n",
      "Test Loss: 1.4430652932784256, Accuracy: 36.00%\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "# 转换标签数据类型\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)  # 确保y是正确的形状\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 训练和测试\n",
    "train_loss, test_loss = [], []\n",
    "train_acc, test_acc = [], []\n",
    "epochs = 30\n",
    "for epoch in range(epochs):  # 训练5个epoch\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_num, correct = 0, 0\n",
    "    s = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 计算准确率\n",
    "        _, predicted = torch.max(output.data, 1)  # 获取每个样本的预测类别\n",
    "        correct += (predicted == target).sum().item()  # 计算正确预测的数量\n",
    "        total_num += target.size(0)  # 计算准确率\n",
    "        \n",
    "        for i in range(5):\n",
    "            s[i] += (predicted == i).sum()\n",
    "        \n",
    "    for i in range(5):\n",
    "        print(f\"训练集预测为{i}的样本数为：{s[i]}\")\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    acc = correct / total_num * 100\n",
    "    train_loss.append(avg_train_loss)\n",
    "    train_acc.append(acc)\n",
    "    print(f\"Average Training Loss: {avg_train_loss}, Accuracy: {acc:.2f}%\")\n",
    "          \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_num, correct = 0, 0\n",
    "    s = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(output.data, 1)  # 获取每个样本的预测类别\n",
    "            correct += (predicted == target).sum().item()  # 计算正确预测的数量\n",
    "            total_num += target.size(0)  # 计算准确率\n",
    "            \n",
    "            for i in range(5):\n",
    "                s[i] += (predicted == i).sum()\n",
    "        \n",
    "    for i in range(5):\n",
    "        print(f\"测试集预测为{i}的样本数为：{s[i]}\")\n",
    "    avg_test_loss = total_loss / len(test_loader)\n",
    "    acc = correct / total_num * 100\n",
    "    test_loss.append(avg_test_loss)\n",
    "    test_acc.append(acc)\n",
    "    print(f\"Test Loss: {avg_test_loss}, Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "torch.save(model, './models/transformer_balance_5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1945e7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T06:26:25.729147Z",
     "start_time": "2024-05-14T06:21:26.571039Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_847634/3590561423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ch6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/d2l/torch.py\u001b[0m in \u001b[0;36mtrain_ch6\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"180.65625pt\" viewBox=\"0 0 238.965625 180.65625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-14T14:26:25.697340</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 180.65625 \n",
       "L 238.965625 180.65625 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "L 0 180.65625 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 143.1 \n",
       "L 225.403125 143.1 \n",
       "L 225.403125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 71.218914 143.1 \n",
       "L 71.218914 7.2 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m60efa2f181\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m60efa2f181\" x=\"71.218914\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(68.037664 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 122.613651 143.1 \n",
       "L 122.613651 7.2 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m60efa2f181\" x=\"122.613651\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(116.251151 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 174.008388 143.1 \n",
       "L 174.008388 7.2 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m60efa2f181\" x=\"174.008388\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(167.645888 157.698438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 225.403125 143.1 \n",
       "L 225.403125 7.2 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m60efa2f181\" x=\"225.403125\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 30.103125 118.174134 \n",
       "L 225.403125 118.174134 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"m77b7d38671\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b7d38671\" x=\"30.103125\" y=\"118.174134\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.5 -->\n",
       "      <g transform=\"translate(7.2 121.973352)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 74.602624 \n",
       "L 225.403125 74.602624 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b7d38671\" x=\"30.103125\" y=\"74.602624\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 78.401843)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 31.031115 \n",
       "L 225.403125 31.031115 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77b7d38671\" x=\"30.103125\" y=\"31.031115\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 1.5 -->\n",
       "      <g transform=\"translate(7.2 34.830334)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 21.879155 13.377273 \n",
       "L 23.934132 14.542704 \n",
       "L 25.989109 15.078106 \n",
       "L 28.044087 15.612504 \n",
       "L 30.099064 15.940374 \n",
       "L 30.103125 15.942381 \n",
       "L 32.158102 19.148799 \n",
       "L 34.213079 19.255149 \n",
       "L 36.268057 19.511205 \n",
       "L 38.323034 19.595486 \n",
       "L 40.378011 19.828796 \n",
       "L 40.382072 19.830353 \n",
       "L 42.43705 20.978067 \n",
       "L 44.492027 21.20663 \n",
       "L 46.547004 21.458654 \n",
       "L 48.601981 21.625153 \n",
       "L 50.656959 21.722838 \n",
       "L 50.66102 21.719613 \n",
       "L 52.715997 22.784955 \n",
       "L 54.770974 22.856074 \n",
       "L 56.825951 22.731149 \n",
       "L 58.880929 22.885118 \n",
       "L 60.935906 22.995173 \n",
       "L 60.939967 22.994898 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 21.879155 136.404275 \n",
       "L 23.934132 136.644665 \n",
       "L 25.989109 136.819276 \n",
       "L 28.044087 136.871151 \n",
       "L 30.099064 136.922727 \n",
       "L 30.103125 136.922195 \n",
       "L 32.158102 136.572907 \n",
       "L 34.213079 136.66081 \n",
       "L 36.268057 136.670378 \n",
       "L 38.323034 136.659913 \n",
       "L 40.378011 136.629595 \n",
       "L 40.382072 136.630217 \n",
       "L 42.43705 136.400687 \n",
       "L 44.492027 136.380057 \n",
       "L 46.547004 136.29305 \n",
       "L 48.601981 136.333862 \n",
       "L 50.656959 136.279057 \n",
       "L 50.66102 136.282284 \n",
       "L 52.715997 135.84815 \n",
       "L 54.770974 136.046382 \n",
       "L 56.825951 136.116047 \n",
       "L 58.880929 136.132491 \n",
       "L 60.935906 136.157069 \n",
       "L 60.939967 136.158176 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 30.103125 135.790834 \n",
       "L 40.382072 135.318798 \n",
       "L 50.66102 134.65307 \n",
       "L 60.939967 134.241294 \n",
       "\" clip-path=\"url(#p31eebe68fe)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 143.1 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 143.1 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 143.1 \n",
       "L 225.403125 143.1 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 140.634375 59.234375 \n",
       "L 218.403125 59.234375 \n",
       "Q 220.403125 59.234375 220.403125 57.234375 \n",
       "L 220.403125 14.2 \n",
       "Q 220.403125 12.2 218.403125 12.2 \n",
       "L 140.634375 12.2 \n",
       "Q 138.634375 12.2 138.634375 14.2 \n",
       "L 138.634375 57.234375 \n",
       "Q 138.634375 59.234375 140.634375 59.234375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 142.634375 20.298438 \n",
       "L 152.634375 20.298438 \n",
       "L 162.634375 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(170.634375 23.798438)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_19\">\n",
       "     <path d=\"M 142.634375 34.976562 \n",
       "L 152.634375 34.976562 \n",
       "L 162.634375 34.976562 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(170.634375 38.476562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 142.634375 49.654688 \n",
       "L 152.634375 49.654688 \n",
       "L 162.634375 49.654688 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(170.634375 53.154688)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p31eebe68fe\">\n",
       "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"135.9\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "d2l.plt.rcParams['figure.figsize'] = (20, 12)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "# 转换标签数据类型\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)  # 确保y是正确的形状\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lr, num_epochs = 1e-4, 20\n",
    "d2l.train_ch6(model, train_loader, test_loader, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95f3231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:17:12.657369Z",
     "start_time": "2024-05-15T07:17:12.457153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 设置全局图表大小\n",
    "plt.rc('figure', figsize=(12, 8))\n",
    "plt.rc('axes', titlesize=18)  # 设置轴标题的字体大小\n",
    "plt.rc('axes', labelsize=14)  # 设置轴标签的字体大小\n",
    "plt.rc('xtick', labelsize=12)  # 设置x轴刻度标签的字体大小\n",
    "plt.rc('ytick', labelsize=12)  # 设置y轴刻度标签的字体大小\n",
    "plt.rc('legend', fontsize=12)  # 设置图例的字体大小\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Loss and acc of the trian process')\n",
    "plt.plot(range(epochs), train_loss, 'b--', label='train_loss')\n",
    "plt.plot(range(epochs), [x / 100 for x in train_acc], 'g--', label = 'train_acc')\n",
    "plt.plot(range(epochs), test_loss, 'r', label = 'test_loss')\n",
    "plt.plot(range(epochs), [x / 100 for x in test_acc], 'black', label = 'test_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc / loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0cce58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T12:10:50.670905Z",
     "start_time": "2024-05-07T12:10:50.670892Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
